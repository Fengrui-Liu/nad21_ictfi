{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nad21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NfIGWOYlDUwGrjoqbcJGGyNaIXIjya7X",
      "authorship_tag": "ABX9TyPaZpWIlIkazjNf8xVBRryH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fengrui-Liu/nad21_ictfi/blob/main/nad21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yaza--7Ly5F"
      },
      "source": [
        "!pip install catboost\r\n",
        "import pandas as pd\r\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n",
        "import numpy as np\r\n",
        "import xgboost as xgb\r\n",
        "import catboost as cab\r\n",
        "import lightgbm as lgb\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.metrics import f1_score, classification_report\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "import pickle\r\n",
        "import gc\r\n",
        "import time\r\n",
        "import os\r\n",
        "gc.enable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mee-_CdBozl3"
      },
      "source": [
        "New features generation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOFDX6cTiudf"
      },
      "source": [
        "def same_subnet(dst,src):\r\n",
        "  dst_subnet = dst.split('.')[:-2]\r\n",
        "  src_subnet = src.split('.')[:-2]\r\n",
        "  if dst_subnet == src_subnet:\r\n",
        "    return 1\r\n",
        "  return 0\r\n",
        "\r\n",
        "def dst_is_broadcastIp(ip):\r\n",
        "  tail = ip.split('.')[-1]\r\n",
        "  if tail == '255':\r\n",
        "    return 1\r\n",
        "  return 0\r\n",
        "\r\n",
        "def subnet(ip):\r\n",
        "  return str(ip.split('.')[0:3])\r\n",
        "\r\n",
        "def net(ip):\r\n",
        "  return int(ip.split('.')[3])\r\n",
        "\r\n",
        "def checkport(spt,dpt):\r\n",
        "  if spt ==0 and dpt==0:\r\n",
        "    return 1\r\n",
        "  return 0\r\n",
        "\r\n",
        "def checkicmp(app):\r\n",
        "  if app == 'icmp':\r\n",
        "    return 1\r\n",
        "  return 0\r\n",
        "\r\n",
        "def checkprobe(group):\r\n",
        "  n = len(group)   \r\n",
        "  net_set = set(group['dst_net'])\r\n",
        "\r\n",
        "  if abs((len(net_set)-1) - (max(net_set) - min(net_set)))<2 and len(net_set)>7 :\r\n",
        "    group['cnt_probe'] = len(net_set)\r\n",
        "    timeStart = time.strptime(group.iloc[0].time, \"%Y-%m-%d %H:%M:%S\")\r\n",
        "    timeEnd = time.strptime(group.iloc[-1].time, \"%Y-%m-%d %H:%M:%S\")\r\n",
        "    dens = len(net_set) / (int(time.mktime(timeEnd)) - int(time.mktime(timeStart)))\r\n",
        "    group['is_probe'] =  0 if dens < 0.1 else 1\r\n",
        "\r\n",
        "  else:\r\n",
        "    group['cnt_probe'] = 0\r\n",
        "    group['is_probe'] = 0\r\n",
        "\r\n",
        "  group['cnt_dpt'] = len(set(group['dpt']))\r\n",
        "  group['cnt_spt'] = len(set(group['spt']))\r\n",
        "  group['cnt_dst_grouped'] = len(set(group['dst']))\r\n",
        "  \r\n",
        "  return group\r\n",
        " "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS01H1dFtxHJ"
      },
      "source": [
        "Drop the uesless features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z2lTDfTXLe4"
      },
      "source": [
        "drop_list =['out (bytes)','in (bytes)','duration','app','sub_dst','dst_net']\r\n",
        "feature_col = []"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWDbih-1WsLN"
      },
      "source": [
        "def trans_df(df, drop = True):\r\n",
        "\r\n",
        "  df['is_broadcast'] = list(map(dst_is_broadcastIp, df['dst']))\r\n",
        "  df['is_subnet'] = list(map(same_subnet,df['dst'],df['src']))\r\n",
        "  df['sub_dst'] = list(map(subnet,df['dst']))\r\n",
        "  df['dst_net'] = list(map(net,df['dst']))\r\n",
        "  df['is_icmp'] = list(map(checkicmp,df['app']))\r\n",
        "  df['is_same_port'] = list(map(checkport,df['spt'],df['dpt']))\r\n",
        "\r\n",
        "  cnt_list = ['cnt_src', 'cnt_serv_dst','cnt_src_slow','cnt_serv_dst_slow', 'cnt_src_conn','cnt_serv_dst_conn']\r\n",
        "\r\n",
        "\r\n",
        "  flat_group_id = df.groupby(['dst'])\r\n",
        "  for feature in cnt_list:\r\n",
        "    df[feature] = flat_group_id[feature].transform('max')\r\n",
        "\r\n",
        "  df['src_count'] = flat_group_id['src'].transform('count')\r\n",
        "\r\n",
        "\r\n",
        "  cnt_list = ['cnt_dst','cnt_serv_src', 'cnt_dst_slow', 'cnt_serv_src_slow', 'cnt_dst_conn', 'cnt_serv_src_conn']\r\n",
        "  flat_group_id = df.groupby(['src','sub_dst'])\r\n",
        "  for feature in cnt_list:\r\n",
        "    df[feature] = flat_group_id[feature].transform('max')\r\n",
        "\r\n",
        "  df['dst_count'] = flat_group_id['dst'].transform('count')\r\n",
        "\r\n",
        "\r\n",
        "  df = flat_group_id.apply(checkprobe)\r\n",
        "\r\n",
        "\r\n",
        "  df.drop(columns = drop_list, inplace = True)\r\n",
        "\r\n",
        "\r\n",
        "  global feature_col\r\n",
        "  feature_col = [ i for i in df.columns if i not in ['time','src','dst','spt','dpt','label','en_label','out (bytes)','in (bytes)','duration','app','proto']]\r\n",
        "  \r\n",
        "  if drop :\r\n",
        "    df.drop_duplicates(subset=feature_col,keep='first',inplace=True)\r\n",
        "  \r\n",
        "  return df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hb6tbgHXuko"
      },
      "source": [
        "df_10 = pd.read_csv('/content/drive/MyDrive/2021_nad_challenge_dataset/training set/1210_firewall.csv')\r\n",
        "df_03 = pd.read_csv('/content/drive/MyDrive/2021_nad_challenge_dataset/training set/1203_firewall.csv')\r\n",
        "df_16 = pd.read_csv('/content/drive/MyDrive/2021_nad_challenge_dataset/training set/1216_firewall.csv')\r\n",
        "\r\n",
        "\r\n",
        "df_10 = trans_df(df_10)\r\n",
        "df_03 = trans_df(df_03)\r\n",
        "df_16 = trans_df(df_16)\r\n",
        "\r\n",
        "df = pd.concat([df_03,df_10,df_16],ignore_index=True,copy=False)\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_A4M6xzt3m3"
      },
      "source": [
        "Ensemble model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv6ktTLWmgw2"
      },
      "source": [
        "class model:\r\n",
        "  def __init__(self,features):\r\n",
        "    self.lb = LabelEncoder()\r\n",
        "    \r\n",
        "    self.xgb_params = {\r\n",
        "      'tree_method':'gpu_hist',\r\n",
        "      'objective':'multi:softprob',\r\n",
        "      # 'objective':'multi:softmax',\r\n",
        "      'metric':'mlogloss',\r\n",
        "      'eval_metric':'mlogloss',\r\n",
        "      'max_delta_step':3,\r\n",
        "      'max_depth':4,\r\n",
        "      'num_class':5\r\n",
        "    }\r\n",
        "    self.lgb_params = {\r\n",
        "      'num_leaves':11,\r\n",
        "      'colsample_bytree':0.8,\r\n",
        "      'subsample':0.8,\r\n",
        "      'max_depth':4,\r\n",
        "      'reg_alpha':0.1,\r\n",
        "      'reg_lambda':0.1,\r\n",
        "      'min_split_gain':0.1,\r\n",
        "      'metric':'multi_logloss',\r\n",
        "      'objective':'multiclass',\r\n",
        "      'num_class':5\r\n",
        "    }\r\n",
        "    self.cab_params = {\r\n",
        "      'iterations': 100,\r\n",
        "      'depth': 3,\r\n",
        "      'allow_writing_files': False,\r\n",
        "      # 'use_best_model':True,\r\n",
        "      'objective':'MultiClass',\r\n",
        "      'early_stopping_rounds':10,\r\n",
        "      'task_type':'GPU',\r\n",
        "      'verbose':False\r\n",
        "    }\r\n",
        "    self.stack_xgb = {\r\n",
        "      'tree_method':'gpu_hist',\r\n",
        "      # 'objective':'multi:softprob',\r\n",
        "      'objective':'multi:softmax',\r\n",
        "      'metric':'mlogloss',\r\n",
        "      'eval_metric':'mlogloss',\r\n",
        "      'max_delta_step':3,\r\n",
        "      'max_depth':4,\r\n",
        "      'num_class':5\r\n",
        "    }\r\n",
        "    self.features = features\r\n",
        "  def fit(self,train):\r\n",
        "\r\n",
        "    train['en_label'] = self.lb.fit_transform(train.label.values)\r\n",
        " \r\n",
        "    train_xgb = xgb.DMatrix(train[self.features],label=train['en_label'])\r\n",
        "    train_lgb = lgb.Dataset(train[self.features],label=train['en_label'])\r\n",
        "    train_cab = cab.Pool(train[self.features],train['en_label'])\r\n",
        "\r\n",
        "  \r\n",
        "    self.bst_xgb = xgb.train(self.xgb_params,dtrain=train_xgb,num_boost_round=100,verbose_eval=False) \r\n",
        " \r\n",
        "    self.bst_lgb = lgb.train(self.lgb_params,train_set=train_lgb,verbose_eval=False)\r\n",
        " \r\n",
        "    self.bst_cab = cab.CatBoost(self.cab_params)\r\n",
        "\r\n",
        "    self.bst_cab.fit(train_cab)\r\n",
        "\r\n",
        "    X = np.concatenate((self.bst_xgb.predict(train_xgb),self.bst_lgb.predict(train[self.features]),self.bst_cab.predict(train_cab)),axis=1)\r\n",
        "\r\n",
        "    train_xgb = xgb.DMatrix(X,label=train['en_label'])\r\n",
        "\r\n",
        "    self.bst = xgb.train(self.stack_xgb,dtrain=train_xgb,num_boost_round=100,verbose_eval=False) \r\n",
        "    \r\n",
        "  def predict(self,data):\r\n",
        "\r\n",
        "    for i in (set(self.features) - set(data.columns)):\r\n",
        "      data[i] = 0\r\n",
        "    test_xgb = xgb.DMatrix(data[self.features])\r\n",
        "    test_cab = cab.Pool(data[self.features])\r\n",
        "\r\n",
        "    X_test_stack = np.concatenate((self.bst_xgb.predict(test_xgb),self.bst_lgb.predict(data[self.features]),self.bst_cab.predict(test_cab)),axis=1)\r\n",
        "  \r\n",
        "    X_test_stack = xgb.DMatrix(X_test_stack)\r\n",
        "\r\n",
        "    label = self.bst.predict(X_test_stack)\r\n",
        "    \r\n",
        "    return self.lb.inverse_transform(label.astype(int))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc8JGr-Wt8nm"
      },
      "source": [
        "Model train and save the pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfZMPiZurf5f"
      },
      "source": [
        "bst_model = model(feature_col)\r\n",
        "bst_model.fit(df)\r\n",
        "model_file = open('/content/drive/MyDrive/114_ictfi_x/model.pkl', 'wb')\r\n",
        "pickle.dump(bst_model,model_file)\r\n",
        "model_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYRoEUHU_KTH",
        "outputId": "6183c8df-e56a-4970-803e-ca1eaf802a5d"
      },
      "source": [
        "model_file = open('/content/drive/MyDrive/114_ictfi_x/model.pkl', 'rb')\r\n",
        "bst_model = pickle.load(model_file)\r\n",
        "\r\n",
        "folder = '/content/drive/MyDrive/2021_nad_challenge_dataset/testing set/'\r\n",
        "\r\n",
        "for root, dirs, files in os.walk(folder):\r\n",
        "  for f in files:\r\n",
        "    if f.endswith('.csv'):\r\n",
        "      test_origin = pd.read_csv(os.path.join(root, f))\r\n",
        "      test_df = test_origin.copy()\r\n",
        "      test_df = trans_df(test_df,drop=False)\r\n",
        "      label = bst_model.predict(test_df)\r\n",
        "      test_origin['label'] = label\r\n",
        "      del test_df\r\n",
        "      gc.collect()\r\n",
        "      print(test_origin.label.value_counts())\r\n",
        "      test_origin.to_csv(os.path.join('/content/drive/MyDrive/114_ictfi_x/', '114_ictfi_x_'+f),index=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal        2118678\n",
            "DDOS-smurf       2141\n",
            "Name: label, dtype: int64\n",
            "Normal                3600977\n",
            "DDOS-smurf                119\n",
            "Probing-Port sweep         81\n",
            "Probing-IP sweep            9\n",
            "Name: label, dtype: int64\n",
            "Normal              2049173\n",
            "Probing-IP sweep        928\n",
            "Probing-Nmap            496\n",
            "DDOS-smurf              113\n",
            "Name: label, dtype: int64\n",
            "Normal                5509470\n",
            "Probing-IP sweep         6818\n",
            "DDOS-smurf               1158\n",
            "Probing-Port sweep        369\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}